# Almacenamiento de alta disponibilidad DRBD para Docker

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![DRBD Version](https://img.shields.io/badge/DRBD-9.x-green.svg)](https://linbit.com/drbd/)
[![Pacemaker](https://img.shields.io/badge/Pacemaker-2.x-orange.svg)](https://clusterlabs.org/)
[![Docker](https://img.shields.io/badge/Docker-20.x+-blue.svg)](https://docker.com/)

> **Laboratorio de alta disponibilidad** que implementa almacenamiento centralizado para Docker usando DRBD + Pacemaker + NFS con failover automÃ¡tico.

## âš¡ CaracterÃ­sticas principales

- **Failover automÃ¡tico** en 30-60 segundos
- **ReplicaciÃ³n sÃ­ncrona** de datos con DRBD
- **Almacenamiento centralizado** vÃ­a NFS
- **Zero downtime** para aplicaciones Docker
- **Arquitectura de 3 nodos** escalable

## DocumentaciÃ³n

### ğŸ“‹ Proceso de ConfiguraciÃ³n Paso a Paso

1. **Crear VMs en Proxmox**
   - Consulte la guÃ­a: [ğŸ—ï¸ **CreaciÃ³n de VMs en Proxmox**](docs/01_PROXMOX.md).
   - Detalla el proceso de creaciÃ³n de VMs desde el shell de Proxmox con instalaciÃ³n automatizada.

2. **Configurar red y post-instalaciÃ³n**
   - Consulte la guÃ­a: [ğŸŒ **ConfiguraciÃ³n de Debian**](docs/02_DEBIAN.md).
   - ConfiguraciÃ³n de red, hostnames y software especÃ­fico por nodo.
   - **MÃ©todo automatizado**: ReconfiguraciÃ³n con `config-network.sh` tras instalaciÃ³n con preseed
   - **MÃ©todo manual**: ConfiguraciÃ³n completa paso a paso para instalaciÃ³n tradicional
   - **ISO personalizada**: [ğŸš€ **CreaciÃ³n de ISO con preseed**](debian/README.md) para crear la ISO de instalaciÃ³n automatizada.

3. **Instalar los paquetes en los nodos DRBD y configurar el clÃºster de almacenamiento**
   - Consulte la guÃ­a: [âš™ï¸ **GuÃ­a de instalaciÃ³n**](docs/INSTALLATION.md).
   - Incluye instrucciones detalladas para configurar DRBD y el clÃºster de almacenamiento.

4. **Instalar Docker en Debian y conectarlo al NFS configurado en el ClÃºster DRBD**
   - Consulte la guÃ­a: [ğŸ”§ **ConfiguraciÃ³n post-instalaciÃ³n**](docs/PROXMOX_DEBIAN.md).
   - Describe cÃ³mo integrar Docker con el almacenamiento NFS proporcionado por el clÃºster DRBD.

5. **Desplegar una WebApp simple en Docker y que se almacene en el NFS**
   - Consulte la guÃ­a: [ğŸ³ Despliegue de WebApp con Docker y NFS](docs/DOCKER_WEBAPP_DEPLOYMENT.md).

6. **Probar dar de baja el nodo primario de DRBD y que la WebApp de Docker siga operativa con el failover**
   - Consulte la guÃ­a: [ğŸ”„ Pruebas de Failover DRBD](docs/DRBD_FAILOVER_TEST.md).

### ğŸ“š GuÃ­as adicionales

| Documento | DescripciÃ³n |
|-----------|-------------|
| [ğŸ“ **Arquitectura del sistema**](docs/ARCHITECTURE.md) | DiseÃ±o completo y componentes de la arquitectura DRBD |
| [ğŸ³ **Despliegue de WebApp con Docker**](docs/DOCKER_WEBAPP_DEPLOYMENT.md) | GuÃ­a para desplegar aplicaciones web usando Docker y NFS |
| [ğŸ”„ **Pruebas de Failover DRBD**](docs/DRBD_FAILOVER_TEST.md) | GuÃ­a completa para probar el failover del clÃºster DRBD |
| [ğŸ“ **Changelog**](CHANGELOG.md) | Historial de cambios del proyecto |
| [ğŸš€ **InstalaciÃ³n automatizada**](debian/README.md) | CreaciÃ³n de ISO personalizada con preseed y configuraciÃ³n dual de red |

## Componentes del sistema

### DescripciÃ³n general de nodos

| Nodo | FunciÃ³n | Rol Principal |
|------|---------|---------------|
| **Node 1** | DRBD Primario | Almacenamiento activo, NFS activo |
| **Node 2** | DRBD Secundario | Replica en standby, NFS standby |
| **Node 3** | Host Docker | EjecuciÃ³n de contenedores |
| **VIP** | IP Flotante | Punto de acceso para alta disponibilidad |

> **ğŸ“ ConfiguraciÃ³n de red detallada**: Ver [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md#configuraciÃ³n-de-red) para el esquema completo de IPs y configuraciÃ³n de red.

### CaracterÃ­sticas principales por nodo

#### ğŸ”µ Node 1 & Node 2: Nodos de almacenamiento DRBD
- ReplicaciÃ³n sincrÃ³nica de datos en tiempo real
- GestiÃ³n automÃ¡tica de failover con Pacemaker
- Servicio NFS para compartir almacenamiento
- Dispositivos: `/dev/sdb1` â†’ `/dev/drbd0` â†’ `/mnt/docker-vol`

#### âš¡ Node 3: Host de ejecuciÃ³n Docker (Stateless)
- **ğŸ’¾ Almacenamiento 100% centralizado en NFS** - Cero almacenamiento local
- **ğŸš€ Optimizado para contenedores** - MÃ¡s CPU y RAM, menos disco
- **ğŸ”„ Completamente desechable** - Puede ser recreado sin pÃ©rdida de datos
- **ğŸŒ ConfiguraciÃ³n dual de red**: Interfaces separadas para administraciÃ³n (ens18) y clÃºster (ens19)
- **ğŸš« Sin persistencia local**: Solo SO en 16GB, TODO en NFS

## Requisitos del sistema

### ğŸ’» Hardware mÃ­nimo recomendado

| Componente | Node 1 & 2 (DRBD) | Node 3 (Docker Stateless) |
|------------|-------------------|--------------------------|
| **CPU** | 2 vCPUs | 4 vCPUs |
| **RAM** | 4GB | 8GB |
| **Almacenamiento** | 24GB SO + 16GB DRBD | 16GB (solo SO) |
| **Red** | 2 interfaces (vmbr2) | 2 interfaces (vmbr2) |
| **FunciÃ³n** | Almacenamiento + NFS | EjecuciÃ³n sin estado |

### ğŸ› ï¸ Software requerido

| Componente | VersiÃ³n | Notas |
|------------|---------|-------|
| **Linux OS** | Debian 12.11+, Ubuntu 22.04+, RHEL/CentOS 9+ | - |
| **DRBD** | 9.x+ | Con mÃ³dulos del kernel |
| **Pacemaker** | 2.x+ | GestiÃ³n de clÃºster |
| **Corosync** | Compatible con Pacemaker | ComunicaciÃ³n del clÃºster |
| **NFS** | v4+ | Cliente y servidor |
| **Docker** | 20.x+ | En Node 3 Ãºnicamente |

## ğŸš€ Inicio rÃ¡pido

1. **Lee la arquitectura**: `cat docs/ARCHITECTURE.md`
2. **Sigue los pasos ordenados** en la secciÃ³n "Proceso de ConfiguraciÃ³n Paso a Paso" anterior
3. **Verifica la instalaciÃ³n**:
   ```bash
   pcs status                    # Estado del clÃºster
   drbdadm status docker-vol     # Estado DRBD
   showmount -e 192.168.10.230   # Servicios NFS
   ```

## âš¡ Proceso de failover automÃ¡tico

La arquitectura implementa un failover completamente automÃ¡tico:

1. ğŸ” **DetecciÃ³n de falla** â†’ Pacemaker detecta falla del nodo primario
2. ğŸ”„ **PromociÃ³n de recursos** â†’ DRBD secundario se promueve a primario  
3. ğŸ“ **Montaje de filesystem** â†’ Sistema de archivos montado en nuevo nodo
4. ğŸŒ **MigraciÃ³n de IP flotante** â†’ IP virtual migra al nodo activo
5. ğŸ”Œ **ReconexiÃ³n automÃ¡tica** â†’ Docker se reconecta transparentemente

**Tiempo de failover tÃ­pico: 30-60 segundos**

## ğŸ”§ Comandos Ãºtiles

### Monitoreo del clÃºster
```bash
# Estado general del clÃºster
pcs status

# Estado especÃ­fico de DRBD
drbdadm status docker-vol

# Verificar servicios NFS
showmount -e 192.168.10.230
```

### Mantenimiento
```bash
# Modo mantenimiento (standby)
pcs cluster standby node1

# Salir de modo mantenimiento
pcs cluster unstandby node1

# Backup de configuraciÃ³n
pcs config backup cluster-backup.tar.bz2
```

Para mÃ¡s detalles sobre monitoreo, mantenimiento y resoluciÃ³n de problemas, consulta la [ğŸ“– **guÃ­a de instalaciÃ³n**](docs/INSTALLATION.md).

## Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## Licencia

Este proyecto estÃ¡ licenciado bajo MIT License. Ver el archivo [LICENSE](LICENSE) para detalles.

## Autor

DiseÃ±o de arquitectura por Rodrigo Ernesto Ãlvarez Aguilera (@incogniadev) - Ingeniero DevOps en Promad Business Solutions

---

**ğŸ“… Ãšltima actualizaciÃ³n**: 2025-07-24 - OptimizaciÃ³n de especificaciones para host Docker stateless con mayor rendimiento

*Esta arquitectura proporciona una base robusta para cargas de trabajo containerizadas que requieren almacenamiento persistente y altamente disponible.*
