# Almacenamiento de alta disponibilidad DRBD para Docker

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![DRBD Version](https://img.shields.io/badge/DRBD-9.x-green.svg)](https://linbit.com/drbd/)
[![Pacemaker](https://img.shields.io/badge/Pacemaker-2.x-orange.svg)](https://clusterlabs.org/)
[![Docker](https://img.shields.io/badge/Docker-20.x+-blue.svg)](https://docker.com/)
[![NFS](https://img.shields.io/badge/NFS-v4-lightblue.svg)](https://en.wikipedia.org/wiki/Network_File_System)
[![Linux](https://img.shields.io/badge/OS-Linux-red.svg)](https://www.linux.org/)
[![High Availability](https://img.shields.io/badge/HA-Cluster-brightgreen.svg)](#)
[![Lab Environment](https://img.shields.io/badge/Environment-Laboratory-purple.svg)](#)
[![Architecture](https://img.shields.io/badge/Type-Architecture%20Design-blue.svg)](#)

## Descripci√≥n

Dise√±o de arquitectura y laboratorio de pruebas para implementar una soluci√≥n de alta disponibilidad para almacenamiento de contenedores Docker utilizando DRBD (Distributed Replicated Block Device) con gesti√≥n de cl√∫ster Pacemaker y servicios NFS. Este repositorio contiene las instrucciones detalladas y configuraciones necesarias para crear un entorno de laboratorio que demuestre esta arquitectura de alta disponibilidad.

## √öltimos cambios

**√öltima actualizaci√≥n:** 2025-07-23

- ‚úÖ **Correcci√≥n integral de inconsistencias** - Unificaci√≥n del esquema de red y especificaciones
- ‚úÖ **Documentaci√≥n de vmbr2** - Explicaci√≥n completa de configuraci√≥n de red dedicada
- ‚úÖ **Especificaciones unificadas** - Hardware consolidado a 4GB RAM en todos los nodos
- ‚úÖ **Herramientas completas** - Documentaci√≥n exhaustiva de dependencias y requisitos
- ‚úÖ **Referencias consistentes** - Eliminaci√≥n de duplicaciones y enlaces verificados

## Caracter√≠sticas principales

- ‚úÖ **Alta disponibilidad** - Failover autom√°tico con tiempo de inactividad m√≠nimo
- ‚úÖ **Consistencia de datos** - Replicaci√≥n s√≠ncrona garantiza integridad
- ‚úÖ **Failover transparente** - Las aplicaciones contin√∫an ejecut√°ndose durante el failover
- ‚úÖ **Almacenamiento centralizado** - Punto √∫nico de gesti√≥n de almacenamiento para contenedores
- ‚úÖ **Escalabilidad** - F√°cil adici√≥n de nuevos hosts Docker como clientes NFS

## Documentaci√≥n

### üìã Gu√≠as disponibles

| Documento | Descripci√≥n |
|-----------|-------------|
| [üìê **Arquitectura del sistema**](docs/ARCHITECTURE.md) | Dise√±o completo y componentes de la arquitectura DRBD |
| [üöÄ **Instalaci√≥n automatizada**](debian/README.md) | Instalaci√≥n desatendida con Debian 12 + preseed (Recomendado) |
| [ü§ñ **Scripts de automatizaci√≥n**](scripts/README.md) | Scripts para creaci√≥n automatizada de VMs en Proxmox (Nuevo) |
| [üèóÔ∏è **Creaci√≥n de VMs en Proxmox**](docs/PROXMOX_VM_CREATION.md) | Gu√≠a detallada para crear VMs desde shell de Proxmox |
| [‚öôÔ∏è **Gu√≠a de instalaci√≥n**](docs/INSTALLATION.md) | Instrucciones generales de instalaci√≥n y configuraci√≥n |
| [üîß **Configuraci√≥n post-instalaci√≥n**](docs/PROXMOX_DEBIAN.md) | Configuraci√≥n espec√≠fica para entornos Proxmox con Debian |
| [üìù **Changelog**](CHANGELOG.md) | Historial de cambios del proyecto |

## Componentes del sistema

### Descripci√≥n general de nodos

| Nodo | Funci√≥n | Rol Principal |
|------|---------|---------------|
| **Node 1** | DRBD Primario | Almacenamiento activo, NFS activo |
| **Node 2** | DRBD Secundario | Replica en standby, NFS standby |
| **Node 3** | Host Docker | Ejecuci√≥n de contenedores |
| **VIP** | IP Flotante | Punto de acceso para alta disponibilidad |

> **üìç Configuraci√≥n de red detallada**: Ver [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md#configuraci√≥n-de-red) para el esquema completo de IPs y configuraci√≥n de red.

### Caracter√≠sticas principales por nodo

#### üîµ Node 1 & Node 2: Nodos de almacenamiento DRBD
- Replicaci√≥n sincr√≥nica de datos en tiempo real
- Gesti√≥n autom√°tica de failover con Pacemaker
- Servicio NFS para compartir almacenamiento
- Dispositivos: `/dev/sdb1` ‚Üí `/dev/drbd0` ‚Üí `/mnt/docker-vol`

#### üü¢ Node 3: Host de ejecuci√≥n Docker
- **Almacenamiento 100% centralizado en NFS**
- Sin datos persistentes locales
- Acceso transparente v√≠a IP flotante
- Configuraci√≥n dual de red para administraci√≥n y cl√∫ster

## Requisitos del sistema

### üíª Hardware m√≠nimo recomendado

|| Componente | Node 1 & 2 (DRBD) | Node 3 (Docker) |
||------------|-------------------|------------------|
|| **CPU** | 2 vCPUs | 2 vCPUs |
|| **RAM** | 4GB | 4GB |
|| **Almacenamiento** | 24GB SO + 16GB DRBD | 32GB |
|| **Red** | 2 interfaces (vmbr2) | 2 interfaces (vmbr2) |

### üõ†Ô∏è Software requerido

| Componente | Versi√≥n | Notas |
|------------|---------|-------|
| **Linux OS** | Debian 12.11+, Ubuntu 22.04+, RHEL/CentOS 9+ | - |
| **DRBD** | 9.x+ | Con m√≥dulos del kernel |
| **Pacemaker** | 2.x+ | Gesti√≥n de cl√∫ster |
| **Corosync** | Compatible con Pacemaker | Comunicaci√≥n del cl√∫ster |
| **NFS** | v4+ | Cliente y servidor |
| **Docker** | 20.x+ | En Node 3 √∫nicamente |

## üöÄ Inicio r√°pido

Para comenzar con la implementaci√≥n del cl√∫ster DRBD de alta disponibilidad, sigue estos pasos:

### 1. Revisa la arquitectura
```bash
# Lee primero la documentaci√≥n de arquitectura
cat docs/ARCHITECTURE.md
```

### 2. Instalaci√≥n automatizada con Debian (Recomendado)

#### Para entornos Proxmox con instalaci√≥n desatendida:

**üéÜ M√©todo 1: Automatizaci√≥n completa con script (Recomendado)**
```bash
# 1. En el host Proxmox, ejecutar script de automatizaci√≥n
./scripts/create-drbd-vms.sh
# Crea autom√°ticamente las 3 VMs con ISO preseed

# 2. Instalaci√≥n escalonada (importante para evitar colisiones IP)
qm start 231  # Node1 - esperar ~10 min
qm start 232  # Node2 - cuando Node1 est√© listo
qm start 233  # Node3 - cuando Node2 est√© listo

# 3. Configurar red en cada VM post-instalaci√≥n
ssh incognia@10.0.0.69
sudo ./config-network.sh
# Repetir para cada VM con IPs finales: 231, 232, 233
```

**üõ†Ô∏è M√©todo 2: Creaci√≥n manual de VMs**
```bash
# 1. Crear VMs manualmente usando la ISO personalizada
# Usar: debian/debian-12.11.0-amd64-preseed.iso
# Ver: docs/PROXMOX_VM_CREATION.md

# 2. La instalaci√≥n se ejecuta autom√°ticamente con:
# - Usuario: incognia (con sudo y SSH)
# - Red est√°tica: 10.0.0.69/8 (reconfigurar post-instalaci√≥n)
# - Paquetes preinstalados: SSH, herramientas de sistema

# 3. Reconfigurar red post-instalaci√≥n
sudo ./config-network.sh

# 4. Seguir gu√≠a de configuraci√≥n post-instalaci√≥n
cat docs/PROXMOX_DEBIAN.md
```

#### Crear ISO personalizada (opcional):
```bash
# Si necesitas generar la ISO personalizada
cd debian/
./create-preseed-iso.sh
# Genera: debian-12.11.0-amd64-preseed.iso
```

### 3. M√©todos de instalaci√≥n alternativos

#### Instalaci√≥n general (cualquier Linux)
```bash
# Sigue la gu√≠a general de instalaci√≥n
cat docs/INSTALLATION.md
```

#### Instalaci√≥n manual para Proxmox + Debian
```bash
# Para instalaci√≥n manual tradicional
cat docs/PROXMOX_DEBIAN.md
```

### 3. Verificaci√≥n post-instalaci√≥n

```bash
# Verificar estado del cl√∫ster DRBD
drbdadm status docker-vol

# Verificar estado de Pacemaker
pcs status

# Verificar montajes NFS
showmount -e 192.168.10.230

# Verificar Docker
docker info
```

## ‚ö° Proceso de failover autom√°tico

La arquitectura implementa un failover completamente autom√°tico:

1. üîç **Detecci√≥n de falla** ‚Üí Pacemaker detecta falla del nodo primario
2. üîÑ **Promoci√≥n de recursos** ‚Üí DRBD secundario se promueve a primario  
3. üìÅ **Montaje de filesystem** ‚Üí Sistema de archivos montado en nuevo nodo
4. üåê **Migraci√≥n de IP flotante** ‚Üí IP virtual migra al nodo activo
5. üîå **Reconexi√≥n autom√°tica** ‚Üí Docker se reconecta transparentemente

**Tiempo de failover t√≠pico: 30-60 segundos**

## üîß Comandos √∫tiles

### Monitoreo del cl√∫ster
```bash
# Estado general del cl√∫ster
pcs status

# Estado espec√≠fico de DRBD
drbdadm status docker-vol

# Verificar servicios NFS
showmount -e 192.168.10.230
```

### Mantenimiento
```bash
# Modo mantenimiento (standby)
pcs cluster standby node1

# Salir de modo mantenimiento
pcs cluster unstandby node1

# Backup de configuraci√≥n
pcs config backup cluster-backup.tar.bz2
```

Para m√°s detalles sobre monitoreo, mantenimiento y resoluci√≥n de problemas, consulta la [üìñ **gu√≠a de instalaci√≥n**](docs/INSTALLATION.md).

## Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'A√±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## Licencia

Este proyecto est√° licenciado bajo MIT License. Ver el archivo [LICENSE](LICENSE) para detalles.

## Autor

Dise√±o de arquitectura por Rodrigo Ernesto √Ålvarez Aguilera (@incogniadev) - Ingeniero DevOps en Promad Business Solutions

---

*Esta arquitectura proporciona una base robusta para cargas de trabajo containerizadas que requieren almacenamiento persistente y altamente disponible.*
